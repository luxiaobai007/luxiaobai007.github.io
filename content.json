{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"https://luxiaobai.cn","root":"/"},"pages":[{"title":"关于","date":"2021-10-11T03:46:23.314Z","updated":"2021-10-11T03:46:23.314Z","comments":false,"path":"about/index.html","permalink":"https://luxiaobai.cn/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"404 Not Found：该页无法显示","date":"2021-10-11T03:46:23.284Z","updated":"2021-10-11T03:46:23.284Z","comments":false,"path":"/404.html","permalink":"https://luxiaobai.cn/404.html","excerpt":"","text":""},{"title":"分类","date":"2021-10-11T03:46:23.360Z","updated":"2021-10-11T03:46:23.360Z","comments":false,"path":"categories/index.html","permalink":"https://luxiaobai.cn/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2021-10-11T03:46:23.337Z","updated":"2021-10-11T03:46:23.337Z","comments":false,"path":"books/index.html","permalink":"https://luxiaobai.cn/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-10-11T03:46:23.386Z","updated":"2021-10-11T03:46:23.386Z","comments":true,"path":"links/index.html","permalink":"https://luxiaobai.cn/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-10-11T03:44:48.818Z","updated":"2021-10-11T03:44:48.818Z","comments":true,"path":"repository/index.html","permalink":"https://luxiaobai.cn/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-10-11T04:05:04.191Z","updated":"2021-10-11T04:05:04.191Z","comments":true,"path":"tags/index.html","permalink":"https://luxiaobai.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis6入门学习(三)","slug":"redis/Redis3","date":"2021-10-11T01:54:21.539Z","updated":"2021-10-11T02:14:06.310Z","comments":true,"path":"2021/10/11/redis/Redis3/","link":"","permalink":"https://luxiaobai.cn/2021/10/11/redis/Redis3/","excerpt":"","text":"[toc] Redis_Jedis_测试Jedis所需要的jar包12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt;&lt;/dependency&gt; 连接Redis注意事项禁用Linux的防火墙：Linux(CentOS7)里执行命令 1systemctl stop/disable firewalld.service Redis.conf中 12#bind 127.0.0.1protected-mode no Jedis常用操作测试程序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class ConnectRedis &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(&quot;127.0.0.1&quot;,6379); String pong = jedis.ping(); System.out.println(&quot;连接成功&quot; + pong); //测试相关数据类型 //Key jedis.set(&quot;k1&quot;,&quot;v1&quot;); jedis.set(&quot;k2&quot;,&quot;v2&quot;); jedis.set(&quot;k3&quot;,&quot;v3&quot;); Set&lt;String&gt; keys = jedis.keys(&quot;*&quot;); System.out.println(keys.size()); for (String key : keys) &#123; System.out.println(key); &#125; System.out.println(&quot;Key API exists &quot; + jedis.exists(&quot;k1&quot;)); System.out.println(&quot;Key API ttl &quot; + jedis.ttl(&quot;k1&quot;)); System.out.println(&quot;Key API get &quot; +jedis.get(&quot;k1&quot;)); //String jedis.mset(&quot;str1&quot;,&quot;v1&quot;,&quot;str2&quot;,&quot;v2&quot;,&quot;str3&quot;,&quot;v3&quot;); System.out.println(&quot;String API &gt;&gt;mset &gt;&gt;&gt; mget &quot; + jedis.mget(&quot;str1&quot;,&quot;str2&quot;,&quot;str3&quot;)); //List jedis.lpush(&quot;mylist&quot;,&quot;l1&quot;,&quot;l2&quot;,&quot;l3&quot;); List&lt;String&gt; mylist = jedis.lrange(&quot;mylist&quot;, 0, -1); for (String s : mylist) &#123; System.out.println(&quot;List API lpush&gt;&gt;lrange: &quot; + s); &#125; //set jedis.sadd(&quot;orders&quot;,&quot;order01&quot;,&quot;order02&quot;,&quot;order3&quot;); Set&lt;String&gt; orders = jedis.smembers(&quot;orders&quot;); for (String order : orders) &#123; System.out.println(&quot;Set API&gt;&gt;sadd&gt;&gt;smembers &quot; + order); &#125; jedis.srem(&quot;orders&quot;,&quot;order02&quot;); //hash jedis.hset(&quot;hash&quot;,&quot;userName&quot;,&quot;lisi&quot;); System.out.println(&quot;hash API:hset&gt;&gt;hget :&quot; + jedis.hget(&quot;hash&quot;,&quot;userName&quot;)); HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put(&quot;telphone&quot;,&quot;15759029165&quot;); map.put(&quot;address&quot;,&quot;longyan&quot;); map.put(&quot;email&quot;,&quot;1575018859@qq.com&quot;); jedis.hmset(&quot;hash2&quot;,map); List&lt;String&gt; result = jedis.hmget(&quot;hash2&quot;, &quot;telphone&quot;, &quot;email&quot;); for (String s : result) &#123; System.out.println(&quot;hash &quot; + s); &#125; //zset jedis.zadd(&quot;zset01&quot;,100d,&quot;z3&quot;); jedis.zadd(&quot;zset01&quot;,90d,&quot;l4&quot;); jedis.zadd(&quot;zset01&quot;,80d,&quot;w5&quot;); jedis.zadd(&quot;zset01&quot;,70d,&quot;z5&quot;); Set&lt;String&gt; zset01 = jedis.zrange(&quot;zset01&quot;, 0, -1); for (String s : zset01) &#123; System.out.println(&quot;zset&gt;&gt; &quot; + s); &#125; jedis.close(); &#125;&#125; Redis-Jedis-实例手机验证码输入手机号，点击发送后随机生成6位数字码，2分钟有效 输入验证码，点击验证，返回成功或失败 每个手机号每天只能输入3次 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class PhoneCode &#123; public static void main(String[] args) &#123; verifyCode(&quot;15759029165&quot;); //getRedisCode(&quot;15759029165&quot;,&quot;438209&quot;); &#125; //1 生成手机验证码 public static String getCode() &#123; Random random = new Random(); String code = &quot;&quot;; for (int i = 0; i &lt; 6; i++) &#123; int ran = random.nextInt(10); code += ran; &#125; return code; &#125; // 2 每个手机每天只能发送3次，验证码放到redis中，设置过期时间 public static void verifyCode(String phone) &#123; Jedis jedis = new Jedis(&quot;121.199.76.44&quot;, 6379); //拼接Key //手机发送次数key String countKey = &quot;VerifyCode&quot; + phone + &quot;:count&quot;; //验证码key String codeKey = &quot;VerifyCode&quot; + phone + &quot;:code&quot;; String count = jedis.get(countKey); if (count == null) &#123; //没有发送次数，第一次发送 //设置发送次数是1 jedis.setex(countKey, 24 * 60 * 60, &quot;1&quot;); &#125; else if (Integer.parseInt(count) &lt;= 2) &#123; jedis.incr(countKey); &#125;else if (Integer.parseInt(count)&gt;2)&#123; System.out.println(&quot;今天发送次数已经超过3次&quot;); jedis.close(); &#125; //发送验证码放到redis里面 String vcode = getCode(); jedis.setex(codeKey,60,vcode); jedis.close(); &#125; //3 验证码校验 public static void getRedisCode(String phone,String code)&#123; Jedis jedis = new Jedis(&quot;121.199.76.44&quot;,6379); String codeKey = &quot;VerifyCode&quot; + phone + &quot;:code&quot;; String redisCode = jedis.get(codeKey); if (redisCode.equals(code))&#123; System.out.println(&quot;成功&quot;); &#125;else &#123; System.out.println(&quot;失败&quot;); &#125; jedis.close(); &#125;&#125; Redis与SpringBoot整合pom.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.luxiaobai&lt;/groupId&gt; &lt;artifactId&gt;spring-redis&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-redis&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- redis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring2.X集成redis所需common-pool2--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; appplication.properties1234567891011121314#Redis服务器地址spring.redis.host=192.168.0.101spring.redis.port=6379#Redis数据库索引（默认为0）spring.redis.database=0#连接超时时间（毫秒）spring.redis.timeout=1800000#连接池最大连接数（使用负值表示没有限制）spring.redis.lettuce.pool.max-active=20#最大阻塞等待时间（负数表示没有限制）spring.redis.lettuce.pool.max-wait=-1#连接池中的最大空闲连接spring.redis.lettuce.pool.min-idle=0 配置类1234567891011121314151617181920212223242526272829303132333435363738394041424344@EnableCaching@Configurationpublic class RedisConfig extends CachingConfigurerSupport &#123; @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer(); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setConnectionFactory(factory); //key序列化方式 template.setKeySerializer(redisSerializer); //value序列化 template.setValueSerializer(jackson2JsonRedisSerializer); //value hashmap序列化 template.setHashValueSerializer(jackson2JsonRedisSerializer); return template; &#125; @Bean public CacheManager cacheManager(RedisConnectionFactory factory) &#123; RedisSerializer&lt;String&gt; redisSerializer = new StringRedisSerializer(); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); //解决查询缓存转换异常的问题 ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); // 配置序列化（解决乱码的问题）,过期时间600秒 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofSeconds(600)) .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer)) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer)) .disableCachingNullValues(); RedisCacheManager cacheManager = RedisCacheManager.builder(factory) .cacheDefaults(config) .build(); return cacheManager; &#125;&#125; controller123456789101112131415@RestController@RequestMapping(&quot;/redisTest&quot;)public class RedisTestController &#123; @Autowired private RedisTemplate redisTemplate; @GetMapping public String testRedist()&#123; //设置值到redis redisTemplate.opsForValue().set(&quot;name&quot;,&quot;lucy&quot;); //从redis取值 String name = (String) redisTemplate.opsForValue().get(&quot;name&quot;); return name; &#125;&#125; Redis事务—-锁机制-秒杀Redis的事务定义Redis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 Redis事务的主要作用就是串联多个命令防止别的命令插队。 Multi、Exec、discard从输入Multi命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入Exec后，Redis会将之前的命令队列中的命令依次执行。 组队的过程中可以通过discard来放弃组队。 123456789101112131415161718192021222324252627282930313233343536127.0.0.1:6379&gt; multiOK127.0.0.1:6379(TX)&gt; set k2 v2QUEUED127.0.0.1:6379(TX)&gt; set k3 v3QUEUED127.0.0.1:6379(TX)&gt; exec1) OK2) OK组队成功,提交成功127.0.0.1:6379&gt; multiOK127.0.0.1:6379(TX)&gt; set m1 v1QUEUED127.0.0.1:6379(TX)&gt; set m2(error) ERR wrong number of arguments for &#x27;set&#x27; command127.0.0.1:6379(TX)&gt; set m3 v3QUEUED127.0.0.1:6379(TX)&gt; exec(error) EXECABORT Transaction discarded because of previous errors.组队阶段报错,提交失败127.0.0.1:6379&gt; multiOK127.0.0.1:6379(TX)&gt; set m1 v1QUEUED127.0.0.1:6379(TX)&gt; incr m1QUEUED127.0.0.1:6379(TX)&gt; set m2 v2QUEUED127.0.0.1:6379(TX)&gt; exec1) OK2) (error) ERR value is not an integer or out of range3) OK组队成功,提交有成功有失败情况 事务的错误处理组队中某个命令出现了报告错误，执行时整个的所有队列都会被取消。 如果执行阶段某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。 事务冲突问题实例 一个请求想给金额减8000 一个请求想给金额减5000 一个请求想给金额减1000 悲观锁 悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁 乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。Redis就是利用这种check-and-set机制实现事务的。 WATCH key[key…]在执行multi之前，先执行watch key1 [key2],可以监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。 123456789127.0.0.1:6379&gt; multiOK127.0.0.1:6379(TX)&gt; decrby balance 10QUEUED127.0.0.1:6379(TX)&gt; incrby debt 10QUEUED127.0.0.1:6379(TX)&gt; exec1) (integer) -102) (integer) 10 unwatch取消 WATCH 命令对所有 key 的监视。 如果在执行 WATCH 命令之后，EXEC 命令或DISCARD 命令先被执行了的话，那么就不需要再执行UNWATCH 了。 Redis事务三特性 单独的隔离操作 事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 没有隔离级别的概念 n 队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行 不保证原子性 n 事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 Redis-事务-秒杀案例解决计数器和人员记录的事务操作 Redis事务–秒杀并发模拟工具ab模拟测试1234567#ubuntusudo apt-get install apache2-utils #CentOSsudo yum -y install httpd-tools#联网yum install httpd-tools vim postfile 模拟表单提交参数,以&amp;符号结尾;存放当前目录。 12prodid=0101&amp;ab -n 2000 -c 200 -k -p ~/postfile -T application/x-www-form-urlencoded http://127.0.0.1:8081/Seckill/doseckill 超卖问题 利用乐观锁淘汰用户，解决超卖问题 连接超时，通过连接池解决 节省每次连接redis服务带来的消耗，把连接好的实例反复利用。通过参数管理连接的行为 12345678910111213141516171819202122232425262728293031//连接池工具类public class JedisPoolUtil &#123; private static volatile JedisPool jedisPool = null; private JedisPoolUtil() &#123; &#125; public static JedisPool getJedisPoolInstance() &#123; if (null == jedisPool) &#123; synchronized (JedisPoolUtil.class) &#123; if (null == jedisPool) &#123; JedisPoolConfig poolConfig = new JedisPoolConfig(); poolConfig.setMaxTotal(200); poolConfig.setMaxTotal(32); poolConfig.setMaxWaitMillis(100 * 1000); poolConfig.setTestOnBorrow(true);//ping PONG jedisPool = new JedisPool(poolConfig, &quot;121.199.76.44&quot;, 6379, 6000); &#125; &#125; &#125; return jedisPool; &#125; public static void release(JedisPool jedisPool, Jedis jedis) &#123; if (null != jedis) &#123; jedisPool.returnResource(jedis); &#125; &#125;&#125; 连接池参数 MaxTotal：控制一个pool可分配多少个jedis实例，通过pool.getResource()来获取；如果赋值为-1，则表示不限制；如果pool已经分配了MaxTotal个jedis实例，则此时pool的状态为exhausted。 maxIdle：控制一个pool最多有多少个状态为idle(空闲)的jedis实例； MaxWaitMillis：表示当borrow一个jedis实例时，最大的等待毫秒数，如果超过等待时间，则直接抛JedisConnectionException； testOnBorrow：获得一个jedis实例的时候是否检查连接可用性（ping()）；如果为true，则得到的jedis实例均是可用的； 库存遗留问题 LUA脚本 Lua 是一个小巧的脚本语言，Lua脚本可以很容易的被C/C++ 代码调用，也可以反过来调用C/C++的函数，Lua并没有提供强大的库，一个完整的Lua解释器不过200k，所以Lua不适合作为开发独立应用程序的语言，而是作为嵌入式脚本语言。很多应用程序、游戏使用LUA作为自己的嵌入式脚本语言，以此来实现可配置性、可扩展性。 这其中包括魔兽争霸地图、魔兽世界、博德之门、愤怒的小鸟等众多游戏插件或外挂。 https://www.w3cschool.cn/lua/ ubuntu 安装 123456#下载编译包curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gztar zxf lua-5.3.0.tar.gzcd lua-5.3.0make linuxmake install 错误原因就是缺少依赖包libreadline-dev 12centos: yum install readline-develUbuntu: sudo apt-get install libreadline-dev. LUA脚本在Redis中的优势将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数。提升性能。LUA脚本是类似redis事务，有一定的原子性，不会被其他命令插队，可以完成一些redis事务性的操作。但是注意redis的lua脚本功能，只有在Redis 2.6以上的版本才可以使用。利用lua脚本淘汰用户，解决超卖问题。 redis 2.6版本以后，通过lua脚本解决争抢问题，实际上是redis 利用其单线程的特性，用任务队列的方式解决多任务并发问题 12345678910111213141516local userid=KEYS[1]; local prodid=KEYS[2];local qtkey=&quot;sk:&quot;..prodid..&quot;:qt&quot;;local usersKey=&quot;sk:&quot;..prodid..&quot;:usr&#x27;; local userExists=redis.call(&quot;sismember&quot;,usersKey,userid);if tonumber(userExists)==1 then return 2;endlocal num= redis.call(&quot;get&quot; ,qtkey);if tonumber(num)&lt;=0 then return 0; else redis.call(&quot;decr&quot;,qtkey); redis.call(&quot;sadd&quot;,usersKey,userid);endreturn 1; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class SecKill_redisByScript &#123; private static final Logger logger = LoggerFactory.getLogger(SecKill_redisByScript.class); public static void main(String[] args) throws IOException &#123; JedisPool jedisPool = JedisPoolUtil.getJedisPoolInstance(); Jedis jedis = jedisPool.getResource(); System.out.println(jedis.ping()); Set&lt;HostAndPort&gt; set = new HashSet&lt;HostAndPort&gt;(); //doSecKill(&quot;201&quot;,&quot;sk:0101&quot;); &#125; static String secKillScript = &quot;local userid=KEYS[1];\\r\\n&quot; + &quot;local prodid=KEYS[2];\\r\\n&quot; + &quot;local qtkey=&#x27;sk:&#x27;..prodid..\\&quot;:qt\\&quot;;\\r\\n&quot; + &quot;local usersKey=&#x27;sk:&#x27;..prodid..\\&quot;:usr\\&quot;;\\r\\n&quot; + &quot;local userExists=redis.call(\\&quot;sismember\\&quot;,usersKey,userid);\\r\\n&quot; + &quot;if tonumber(userExists)==1 then \\r\\n&quot; + &quot; return 2;\\r\\n&quot; + &quot;end\\r\\n&quot; + &quot;local num= redis.call(\\&quot;get\\&quot; ,qtkey);\\r\\n&quot; + &quot;if tonumber(num)&lt;=0 then \\r\\n&quot; + &quot; return 0;\\r\\n&quot; + &quot;else \\r\\n&quot; + &quot; redis.call(\\&quot;decr\\&quot;,qtkey);\\r\\n&quot; + &quot; redis.call(\\&quot;sadd\\&quot;,usersKey,userid);\\r\\n&quot; + &quot;end\\r\\n&quot; + &quot;return 1&quot;; static String secKillScript2 = &quot;local userExists=redis.call(\\&quot;sismember\\&quot;,\\&quot;&#123;sk&#125;:0101:usr\\&quot;,userid);\\r\\n&quot; + &quot; return 1&quot;; public static boolean doSecKill(String uid, String prodid) throws IOException &#123; JedisPool jedisPool = JedisPoolUtil.getJedisPoolInstance(); Jedis jedis = jedisPool.getResource(); String sha1 = jedis.scriptLoad(secKillScript); Object result = jedis.evalsha(sha1, 2, uid, prodid); String reString = String.valueOf(result); if (&quot;0&quot;.equals(reString)) &#123; System.out.println(&quot;已抢空！！&quot;); &#125; else if (&quot;1&quot;.equals(reString)) &#123; System.out.println(&quot;抢购成功！！&quot;); &#125; else if (&quot;2&quot;.equals(reString)) &#123; System.out.println(&quot;该用户已抢过！！&quot;); &#125; else &#123; System.out.println(&quot;抢购异常！！&quot;); &#125; jedis.close(); return true; &#125;&#125;","categories":[],"tags":[]},{"title":"Redis6入门学习(二)","slug":"redis/Redis2","date":"2021-10-08T03:01:30.257Z","updated":"2021-10-11T01:54:16.403Z","comments":true,"path":"2021/10/08/redis/Redis2/","link":"","permalink":"https://luxiaobai.cn/2021/10/08/redis/Redis2/","excerpt":"","text":"[toc] Redis6配置文件12//配置文件路径vim /etc/redis/redis.conf Units单位配置大小单位,开头定义了一些基本的度量单位，只支持bytes，不支持bit大小写不敏感 INCLUDES包含 类似jsp中的include，多实例的情况可以把公用的配置文件提取出来 网络相关配置bind默认情况bind=127.0.0.1只能接受本机的访问请求,不写的情况下，无限制接受任何ip地址的访问 生产环境肯定要写你应用服务器的地址；服务器是需要远程访问的，所以需要将其注释掉 如果开启了protected-mode，那么在没有设定bind ip且没有设密码的情况下，Redis只允许接受本机的响应 保存配置,重启服务 123redis-clishutdownredis-server /etc/redis.conf protected-modeprotected-mode配置，默认是yes，即开启。设置外部网络连接redis服务，设置方式如下： 1、关闭protected-mode模式，此时外部网络可以直接访问 2、开启protected-mode保护模式，需配置bind ip或者设置访问密码 tcp-backlog设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。 在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。 注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值（128），所以需要确认增大/proc/sys/net/core/somaxconn和/proc/sys/net/ipv4/tcp_max_syn_backlog（128）两个值来达到想要的效果 timeout一个空闲的客户端维持多少秒会关闭，0表示关闭该功能。即永不关闭。 tcp-keepalive对访问客户端的一种心跳检测，每个n秒检测一次。单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60 GENERAL通用daemonize是否为后台进程，设置为yes 守护进程，后台启动 pidfile存放pid文件的位置，每个实例会产生一个不同的pid文件 loglevel指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为notice 四个级别根据使用阶段来选择，生产环境选择notice 或者warning logfiledatabases16设定库的数量 默认16，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id SECURITY安全设置密码 访问密码的查看、设置和取消 在命令中设置密码，只是临时的。重启redis服务器，密码就还原了。 永久设置，需要再配置文件中进行设置。 12345678910root@iZbp13941xpzjmefjge9chZ:/etc# redis-cli127.0.0.1:6379&gt; config get requirepass1) &quot;requirepass&quot;2) &quot;&quot;127.0.0.1:6379&gt; config set requirepass &quot;123456&quot;OK127.0.0.1:6379&gt; config get requirepass(error) NOAUTH Authentication required.127.0.0.1:6379&gt; auth 123456OK LIMITS限制maxclients设置redis同时可以与多少个客户端进行连接。 默认情况下为10000个客户端。 如果达到了此限制，redis则会拒绝新的连接请求，并且向这些连接请求方发出“max number of clients reached”以作回应。 maxmemory 建议必须设置，否则，将内存占满，造成服务器宕机 设置redis可以使用的内存量。一旦到达内存使用上限，redis将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。 如果redis无法根据移除规则来移除内存中的数据，或者设置了“不允许移除”，那么redis则会针对那些需要申请内存的指令返回错误信息，比如SET、LPUSH等。 但是对于无内存申请的指令，仍然会正常响应，比如GET等。如果你的redis是主redis（说明你的redis有从redis），那么在设置内存使用上限时，需要在系统中留出一些内存空间给同步队列缓存，只有在你设置的是“不移除”的情况下，才不用考虑这个因素。 maxmemory-policyvolatile-lru：使用LRU算法移除key，只对设置了过期时间的键；（最近最少使用） allkeys-lru：在所有集合key中，使用LRU算法移除key volatile-random：在过期集合中移除随机的key，只对设置了过期时间的键 allkeys-random：在所有集合key中，移除随机的key volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key noeviction：不进行移除。针对写操作，只是返回错误信息 maxmemory-samples 设置样本数量，LRU算法和最小TTL算法都并非是精确的算法，而是估算值，所以你可以设置样本的大小，redis默认会检查这么多个key并选择其中LRU的那个。 一般设置3到7的数字，数值越小样本越不准确，但性能消耗越小。 Redis6的发布和订阅 Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。 Redis 客户端可以订阅任意数量的频道。 Redis的发布和订阅1、客户端可以订阅频道 2、当给这个频道发布消息后，消息就会发送给订阅的客户端 发布订阅命令行实现1、 打开一个客户端订阅channel1 1SUBSCRIBE channel1 2、打开另一个客户端，给channel1发布消息hello 1127.0.0.1:6379&gt; publish channel hello (integer) 1 返回的1是订阅者数量 3、打开第一个客户端可以看到发送的消息 发布的消息没有持久化，如果在订阅的客户端收不到hello，只能收到订阅后发布的消息 Redis6新数据类型Bitmaps 现代计算机用二进制（位） 作为信息的基础单位， 1个字节等于8位， 例如“abc”字符串是由3个字节组成， 但实际在计算机存储时将其用二进制表示， “abc”分别对应的ASCII码分别是97、 98、 99， 对应的二进制分别是01100001、 01100010和01100011 合理地使用操作位能够有效地提高内存使用率和开发效率。 Redis提供了Bitmaps这个“数据类型”可以实现对位的操作： （1） Bitmaps本身不是一种数据类型， 实际上它就是字符串（key-value） ， 但是它可以对字符串的位进行操作。 （2） Bitmaps单独提供了一套命令， 所以在Redis中使用Bitmaps和使用字符串的方法不太相同。 可以把Bitmaps想象成一个以位为单位的数组， 数组的每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量。 命令setbit 1setbit &lt;key&gt;&lt;offset&gt;&lt;value&gt; 设置Bitmaps中某个偏移量的值（0或1） offset:偏移量从0开始 实例每个独立用户是否访问过网站存放在Bitmaps中， 将访问的用户记做1， 没有访问的用户记做0， 用偏移量作为用户的id。 设置键的第offset个位的值（从0算起） ， 假设现在有20个用户，userid=1， 6， 11， 15， 19的用户对网站进行了访问， 那么当前Bitmaps初始化结果如图 unique:users:20201106代表2020-11-06这天的独立访问用户的Bitmaps 12345678910127.0.0.1:6379&gt; setbit unique:users:20201106 1 1(integer) 0127.0.0.1:6379&gt; setbit unique:users:20201106 6 1(integer) 0127.0.0.1:6379&gt; setbit unique:users:20201106 11 1(integer) 0127.0.0.1:6379&gt; setbit unique:users:20201106 15 1(integer) 0127.0.0.1:6379&gt; setbit unique:users:20201106 19 1(integer) 0 很多应用的用户id以一个指定数字（例如10000） 开头， 直接将用户id和Bitmaps的偏移量对应势必会造成一定的浪费， 通常的做法是每次做setbit操作时将用户id减去这个指定数字。 在第一次初始化Bitmaps时， 假如偏移量非常大， 那么整个初始化过程执行会比较慢， 可能会造成Redis的阻塞。 getbit1getbit &lt;key&gt; &lt;offset&gt; 获取Bitmaps中某个偏移量的值 获取键的第offset位的值(从0开始算 实例获取 id=8的用户是否在2020-11-06这天访问过， 返回0说明没有访问过： 123456127.0.0.1:6379&gt; getbit unique:users:20201106 8(integer) 0127.0.0.1:6379&gt; getbit unique:users:20201106 1(integer) 1127.0.0.1:6379&gt; getbit unique:users:20201106 100(integer) 0 ==因为100根本不存在,所以返回0== bitcount统计字符串被设置为1的bit数。一般情况下，给定的整个字符串都会被进行计数，通过指定额外的 start 或 end 参数，可以让计数只在特定的位上进行。start 和 end 参数的设置，都可以使用负数值：比如 -1 表示最后一个位，而 -2 表示倒数第二个位，start、end 是指bit组的字节的下标数，二者皆包含。 1bitcount&lt;key&gt;[start end] 统计字符串从start字节到end字节比特值为1的数量 实例2022-11-06这天的独立访问用户数量 12127.0.0.1:6379&gt; bitcount unique:users:20201106(integer) 5 start和end代表起始和结束字节数， 下面操作计算用户id在第1个字节到第3个字节之间的独立访问用户数， 对应的用户id是11， 15， 19。 123127.0.0.1:6379&gt; bitcount unique:users:20201106 1 3(integer) 3##1个字节8位 redis的setbit设置或清除的是bit位置，而bitcount计算的是byte位置。 bitop1bitop and(or/not/xor) &lt;destkey&gt; [key...] bitop是一个复合操作， 它可以做多个Bitmaps的and（交集） 、 or（并集） 、 not（非） 、 xor（异或） 操作并将结果保存在destkey中。 123456789101112131415161718127.0.0.1:6379&gt; setbit unique:users:20201104 1 1(integer) 0127.0.0.1:6379&gt; setbit unique:users:20201104 2 1(integer) 0127.0.0.1:6379&gt; setbit unique:users:20201104 5 1(integer) 0127.0.0.1:6379&gt; setbit unique:users:20201104 9 1(integer) 0127.0.0.1:6379&gt; setbit unique:users:20201103 0 1(integer) 0127.0.0.1:6379&gt; setbit unique:users:20201103 1 1(integer) 0127.0.0.1:6379&gt; setbit unique:users:20201103 4 1(integer) 0127.0.0.1:6379&gt; setbit unique:users:20201103 9 1(integer) 0127.0.0.1:6379&gt; bitop and unique:users:and:20201104_03 unique:users:20201103 unique:users:20201104(integer) 2 Bitmaps与set对比假设网站有1亿用户， 每天独立访问的用户有5千万， 如果每天用集合类型和Bitmaps分别存储活跃用户可以得到表 set和Bitmaps存储独立用户空间对比 数据类型 一天 一个月 一年 集合类型 400MB 12GB 144GB Bitmaps 12.5MB 375MB 4.5GB 很明显， 这种情况下使用Bitmaps能节省很多的内存空间， 尤其是随着时间推移节省的内存还是非常可观的 但Bitmaps并不是万金油， 假如该网站每天的独立访问用户很少， 例如只有10万（大量的僵尸用户） ， 那么两者的对比如下表所示， 很显然， 这时候使用Bitmaps就不太合适了， 因为基本上大部分位都是0 set和Bitmaps存储一天活跃用户对比（独立用户比较少) 数据类型 每个userid占用空间 需要存储的用户量 全部内存量 集合类型 64位 100000 64位*100000 = 800KB Bitmaps 1位 100000000 1位*100000000 = 12.5MB HyperLogLog 在工作当中，我们经常会遇到与统计相关的功能需求，比如统计网站PV（PageView页面访问量）,可以使用Redis的incr、incrby轻松实现。但像UV（UniqueVisitor，独立访客）、独立IP数、搜索记录数等需要去重和计数的问题如何解决？这种求集合中不重复元素个数的问题称为基数问题。解决基数问题有很多种方案： （1）数据存储在MySQL表中，使用distinct count计算不重复个数 （2）使用Redis提供的hash、set、bitmaps等数据结构来处理 以上的方案结果精确，但随着数据不断增加，导致占用空间越来越大，对于非常大的数据集是不切实际的。能否能够降低一定的精度来平衡存储空间？ Redis推出了HyperLogLog. Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。什么是基数?比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。 命令pfadd1pfadd &lt;key&gt;&lt;element&gt;[element...] 添加指定元素到HyperLogLog中 将所有元素添加到指定HyperLogLog数据结构中。如果执行命令后HLL估计的近似基数发生变化，则返回1，否则返回0。 pfcount12345678910111213141516pfcount &lt;key&gt;[key...] 计算HLL的近似基数，可以计算多个HLL127.0.0.1:6379&gt; pfadd hll1 &quot;redis&quot; &quot;mysql&quot;(integer) 1127.0.0.1:6379&gt; pfadd hll1 &quot;redis&quot;(integer) 0127.0.0.1:6379&gt; pfcount hll1(integer) 2127.0.0.1:6379&gt; pfadd hll1 &quot;mongodb&quot;(integer) 1127.0.0.1:6379&gt; pfadd h2 &quot;redis&quot;(integer) 1127.0.0.1:6379&gt; pfadd h2 &quot;java&quot;(integer) 1127.0.0.1:6379&gt; pfcount hll1 h2(integer) 4 pfmerge1234567pfmerge &lt;destkey&gt;&lt;sourcekey&gt;[sourcekey...] . 将一个或多个HLL合并后的结果存储在另一个HLL中 比如每月活跃用户可以使用每天的活跃用户来合并计算可得127.0.0.1:6379&gt; pfcount hll1 h2(integer) 4127.0.0.1:6379&gt; pfmerge h3 hll1 h2OK127.0.0.1:6379&gt; pfcount h3(integer) 4 Geospatial GEO，Geographic，地理信息的缩写。该类型，就是元素的2维坐标，在地图上就是经纬度。redis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度Hash等常见操作。 命令geoadd 1geoadd &lt;key&gt;&lt; longitude&gt;&lt;latitude&gt;&lt;member&gt; [longitude latitude member...] 添加地理位置（经度，纬度，名称） 两极无法直接添加，一般会下载城市数据，直接通过 Java 程序一次性导入。有效的经度从 -180 度到 180 度。有效的纬度从 -85.05112878 度到 85.05112878 度。当坐标位置超出指定范围时，该命令将会返回一个错误。已经添加的数据，是无法再次往里面添加的。 geopos1234geodist&lt;key&gt;&lt;member1&gt;&lt;member2&gt; [m|km|ft|mi ] 获取两个位置之间的直线距离127.0.0.1:6379&gt; geodist china:city beijing shanghai km&quot;1068.1535&quot; 单位： m 表示单位为米[默认值]。 km 表示单位为千米。 mi 表示单位为英里。 ft 表示单位为英尺。 如果用户没有显式地指定单位参数， 那么 GEODIST 默认使用米作为单位 georadius12345georadius&lt;key&gt;&lt; longitude&gt;&lt;latitude&gt;radius m|km|ft|mi 以给定的经纬度为中心，找出某一半径内的元素经度 纬度 距离 单位127.0.0.1:6379&gt; georadius china:city 110 30 1000 km1) &quot;chonggin&quot;2) &quot;shenzhen&quot;","categories":[],"tags":[]},{"title":"Redis6入门学习(一)","slug":"redis/Redis1","date":"2021-10-08T02:34:57.707Z","updated":"2021-10-11T02:51:03.663Z","comments":true,"path":"2021/10/08/redis/Redis1/","link":"","permalink":"https://luxiaobai.cn/2021/10/08/redis/Redis1/","excerpt":"","text":"[toc] NoSQL数据库NoSQL数据库概述NoSQL(NoSQL = Not Only SQL )，意即“不仅仅是SQL”，泛指非关系型的数据库。NoSQL 不依赖业务逻辑方式存储，而以简单的key-value模式存储。因此大大的增加了数据库的扩展能力。 不遵循SQL标准。 不支持ACID。(事务的4个特征:原子性、一致性、隔离性和持久性) 远超于SQL的性能。 适用场景 对数据高并发的读写 海量数据的读写 对数据高可扩展性的 不适用的场景 需要事务支持 基于sql的结构化查询存储，处理复杂的关系,需要即席查询。 （用不着sql的和用了sql也不行的情况，请考虑用NoSql） Memcache 很早出现的NoSql数据库 数据都在内存中，一般不持久化 支持简单的key-value模式，支持类型单一 一般是作为缓存数据库辅助持久化的数据库 Redis 几乎覆盖了Memcached的绝大部分功能 数据都在内存中，支持持久化，主要用作备份恢复 除了支持简单的key-value模式，还支持多种数据结构的存储，比如 list、set、hash、zset等。 一般是作为缓存数据库辅助持久化的数据库 MongoDB 高性能、开源、模式自由(schema free)的文档型数据库 数据都在内存中， 如果内存不足，把不常用的数据保存到硬盘 虽然是key-value模式，但是对value（尤其是json）提供了丰富的查询功能 支持二进制数据及大型对象 可以根据数据的特点替代RDBMS ，成为独立的数据库。或者配合RDBMS，存储特定的数据 行式存储数据库 列式存储数据库 图关系型数据库主要应用：社会关系，公共交通网络，地图及网络拓谱(n*(n-1)/2) Cassandra[kəˈsændrə]Apache Cassandra是一款免费的开源NoSQL数据库，其设计目的在于管理由大量商用服务器构建起来的庞大集群上的海量数据集(数据量通常达到PB级别)。在众多显著特性当中，Cassandra最为卓越的长处是对写入及读取操作进行规模调整，而且其不强调主集群的设计思路能够以相对直观的方式简化各集群的创建与扩展流程。 HbaseHBase是Hadoop项目中的数据库。它用于需要对大量的数据进行随机、实时的读写操作的场景中。 HBase的目标就是处理数据量非常庞大的表，可以用普通的计算机处理超过10亿行数据，还可处理有数百万列元素的数据表。 Redis安装介绍 Redis是一个开源的key-value存储系统。 和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型）。 这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。 在此基础上，Redis支持各种不同方式的排序。 与memcached一样，为了保证效率，数据都是缓存在内存中。 区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件。 并且在此基础上实现了master-slave(主从)同步 适用场景配合关系型数据库做高速缓存 高频次，热门访问的数据，降低数据库IO 分布式架构，做session共享 多样的数据结构存储持久化数据 Ubuntu安装Redis12345678910111213#安装sudo apt updatesudo apt install redis-server#启动redis-server#查看redis是否启动redis-cliroot@iZbp13941xpzjmefjge9chZ:~# redis-cli127.0.0.1:6379&gt; auth &quot;lxb991209&quot;127.0.0.1:6379&gt; pingPONG Ubuntu默认目录 /usr/bin123456redis-benchmark:性能测试工具，可以在自己本机运行，看看自己本机性能如何redis-check-aof：修复有问题的AOF文件，rdb和aof后面讲 redis-check-dump：修复有问题的dump.rdb文件redis-sentinel：Redis集群使用redis-server：Redis服务器启动命令redis-cli：客户端，操作入口 前台启动(不推荐)1redis-server 后台启动(推荐)12cp -r redis.conf /etc/redis.confredis-server /etc/redis.conf 相关知识1234567默认端口6379默认16个数据库，类似数组下标从0开始，初始默认使用0号库使用命令 select &lt;dbid&gt;来切换数据库。如: select 8统一密码管理，所有库同样密码。dbsize查看当前数据库的key的数量flushdb清空当前库flushall通杀全部库 Redis是单线程+多路IO复用技术 多路复用是指使用一个线程来检查多个文件描述符（Socket）的就绪状态，比如调用select和poll函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启动线程执行（比如使用线程池） 串行 vs 多线程+锁（memcached） vs 单线程+多路IO复用(Redis) （ 与Memcache三点不同: 支持多数据类型 支持持久化 单线程+多路IO复用 ） 五大数据类型Redis键(Key)123456789101112keys * ==查看当前库所有key== (匹配：keys *1)exists key 判断某个key是否存在type key 查看你的key是什么类型del key 删除指定的key数据unlink key 根据value选择非阻塞删除 仅将keys从keyspace 元数据中删除，真正的删除会在后续异步操作。expire key 10 10秒钟：为给定的key设置过期时间ttl key 查看还有多少秒过期，-1表示永不过期，-2表示已过期 select 命令切换数据库dbsize 查看当前数据库的key的数量flushdb 清空当前库flushall 通杀全部库 Redis字符串(String) String是Redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。 String类型是二进制安全的。意味着Redis的string可以包含任何数据。比如jpg图片或者序列化的对象。 String类型是Redis最基本的数据类型，一个Redis中字符串value最多可以是512M 常用命令12345678910111213141516171819202122232425set &lt;key&gt;&lt;value&gt; 添加键值对 *NX：当数据库中key不存在时，可以将key-value添加数据库 *XX：当数据库中key存在时，可以将key-value添加数据库，与NX参数互斥 *EX：key的超时秒数 *PX：key的超时毫秒数，与EX互斥get &lt;key&gt; 查询对应键值append &lt;key&gt;&lt;value&gt; 将给定的&lt;value&gt; 追加到原值的末尾strlen &lt;key&gt; 获得值的长度setnx &lt;key&gt;&lt;value&gt; 只有在 key 不存在时 设置 key 的值 incr &lt;key&gt; 将 key 中储存的数字值增1,只能对数字值操作，如果为空，新增值为1decr &lt;key&gt; 将 key 中储存的数字值减1,只能对数字值操作，如果为空，新增值为-1incrby / decrby &lt;key&gt; &lt;步长&gt; 将 key 中储存的数字值增减。自定义步长。 mset &lt;key1&gt;&lt;value1&gt;&lt;key2&gt;&lt;value2&gt; ..... 同时设置一个或多个 key-value对 mget &lt;key1&gt;&lt;key2&gt;&lt;key3&gt; ..... 同时获取一个或多个 value msetnx &lt;key1&gt;&lt;value1&gt;&lt;key2&gt;&lt;value2&gt; ..... 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。原子性，有一个失败则都失败 getrange &lt;key&gt;&lt;起始位置&gt;&lt;结束位置&gt; 获得值的范围，类似java中的substring，前包，后包setrange &lt;key&gt;&lt;起始位置&gt;&lt;value&gt; 用 &lt;value&gt; 覆写&lt;key&gt;所储存的字符串值，从&lt;起始位置&gt;开始(索引从0开始)。 setex &lt;key&gt;&lt;过期时间&gt;&lt;value&gt; 设置键值的同时，设置过期时间，单位秒。getset &lt;key&gt;&lt;value&gt; 以新换旧，设置了新值同时获得旧值。 incr key :对存储在指定key的数值执行原子的加1操作 所谓原子操作是指不会被线程调度机制打断的操作； 这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch （切换到另一个线程）。 （1）在单线程中， 能够在单条指令中完成的操作都可以认为是”原子操作”，因为中断只能发生于指令之间。 （2）在多线程中，不能被其它进程（线程）打断的操作就叫原子操作。 Redis单命令的原子性主要得益于Redis的单线程 数据结构String的数据结构为简单动态字符串(Simple Dynamic String,缩写SDS)。是可以修改的字符串，内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配. 内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间。需要注意的是字符串最大长度为512M。 Redis列表(List)简介单键多值 Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。 常用命令12345678910lpush/rpush &lt;key&gt;&lt;value1&gt;&lt;value2&gt;&lt;value3&gt; .... 从左边/右边插入一个或多个值。lpop/rpop &lt;key&gt; 从左边/右边吐出一个值。值在键在，值光键亡。rpoplpush &lt;key1&gt;&lt;key2&gt; 从&lt;key1&gt;列表右边吐出一个值，插到&lt;key2&gt;列表左边。lrange &lt;key&gt;&lt;start&gt;&lt;stop&gt; 按照索引下标获得元素(从左到右)lrange mylist 0 -1 0左边第一个，-1右边第一个，（0-1表示获取所有）lindex &lt;key&gt;&lt;index&gt; 按照索引下标获得元素(从左到右)llen &lt;key&gt; 获得列表长度linsert &lt;key&gt; before/after &lt;value&gt;&lt;newvalue&gt; 在&lt;value&gt;的后面插入&lt;newvalue&gt;插入值lrem &lt;key&gt;&lt;n&gt;&lt;value&gt; 从左边删除n个value(从左到右)lset&lt;key&gt;&lt;index&gt;&lt;value&gt; 将列表key下标为index的值替换成value 数据结构List的数据结构为==快速链表quickList。== 首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是ziplist，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的时候才会改成quicklist。因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是int类型的数据，结构上还需要两个额外的指针prev和next。 Redis将链表和ziplist结合起来组成了quicklist。也就是将多个ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。 Redis集合(Set)简介Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。Redis的Set是string类型的无序集合。它底层其实是一个value为null的hash表，所以添加，删除，查找的**复杂度都是O(1)**。 一个算法，随着数据的增加，执行时间的长短，如果是O(1)，数据增加，查找数据的时间不变 常用命令1234567891011sadd &lt;key&gt;&lt;value1&gt;&lt;value2&gt; ..... 将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略smembers &lt;key&gt; 取出该集合的所有值。sismember &lt;key&gt;&lt;value&gt; 判断集合&lt;key&gt;是否为含有该&lt;value&gt;值，有1，没有0scard&lt;key&gt; 返回该集合的元素个数。srem &lt;key&gt;&lt;value1&gt;&lt;value2&gt; .... 删除集合中的某个元素。spop &lt;key&gt; 随机从该集合中吐出一个值。srandmember &lt;key&gt;&lt;n&gt; 随机从该集合中取出n个值。不会从集合中删除 。smove &lt;source&gt;&lt;destination&gt;value 把集合中一个值从一个集合移动到另一个集合sinter &lt;key1&gt;&lt;key2&gt; 返回两个集合的交集元素。sunion &lt;key1&gt;&lt;key2&gt; 返回两个集合的并集元素。sdiff &lt;key1&gt;&lt;key2&gt; 返回两个集合的差集元素(key1中的，不包含key2中的) 数据结构Set数据结构是dict字典，字典是用哈希表实现的。Java中HashSet的内部实现使用的是HashMap，只不过所有的value都指向同一个对象。Redis的set结构也是一样，它的内部也使用hash结构，所有的value都指向同一个内部值。 Redis哈希(hash)简介Redis hash 是一个键值对集合。 Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 类似Java里面的Map&lt;String,Object&gt; 用户ID为查找的key，存储的value用户对象包含姓名，年龄，生日等信息，如果用普通的key/value结构来存储 通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据了，既不需要重复存储数据，也不会带来序列化和并发修改控制的问题 常用命令12345678hset &lt;key&gt;&lt;field&gt;&lt;value&gt; 给&lt;key&gt;集合中的&lt;field&gt;键赋值&lt;value&gt;hget &lt;key1&gt;&lt;field&gt; 从&lt;key1&gt;集合&lt;field&gt;取出 valuehmset &lt;key1&gt;&lt;field1&gt;&lt;value1&gt;&lt;field2&gt;&lt;value2&gt;... 批量设置hash的值hexists&lt;key1&gt;&lt;field&gt; 查看哈希表 key 中，给定域 field 是否存在。hkeys &lt;key&gt; 列出该hash集合的所有fieldhvals &lt;key&gt; 列出该hash集合的所有valuehincrby &lt;key&gt;&lt;field&gt;&lt;increment&gt; 为哈希表 key 中的域 field 的值加上增量 1 -1hsetnx &lt;key&gt;&lt;field&gt;&lt;value&gt; 将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在 . 数据结构Hash类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。当field-value长度较短且个数较少时，使用ziplist，否则使用hashtable。 Redis有序集合(Zset)简介Redis有序集合zset与普通集合set非常相似，是一个没有重复元素的字符串集合。 不同之处是有序集合的每个成员都关联了一个评分（score）,这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了 。 因为元素是有序的, 所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。 访问有序集合的中间元素也是非常快的,因此你能够使用有序集合作为一个没有重复成员的智能列表。 常用命令12345678zadd &lt;key&gt;&lt;score1&gt;&lt;value1&gt;&lt;score2&gt;&lt;value2&gt;… 将一个或多个 member 元素及其 score 值加入到有序集 key 当中。zrange &lt;key&gt;&lt;start&gt;&lt;stop&gt; [WITHSCORES] 返回有序集 key 中，下标在&lt;start&gt;&lt;stop&gt;之间的元素 带WITHSCORES，可以让分数一起和值返回到结果集。zrangebyscore key minmax [withscores] [limit offset count] 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。zrevrangebyscore key maxmin [withscores] [limit offset count] 同上，改为从大到小排列。zincrby &lt;key&gt;&lt;increment&gt;&lt;value&gt; 为元素的score加上增量zrem &lt;key&gt;&lt;value&gt; 删除该集合下，指定值的元素zcount &lt;key&gt;&lt;min&gt;&lt;max&gt; 统计该集合，分数区间内的元素个数zrank &lt;key&gt;&lt;value&gt; 返回该值在集合中的排名，从0开始。 数据结构SortedSet(zset)是Redis提供的一个非常特别的数据结构，一方面它等价于Java的数据结构Map&lt;String, Double&gt;，可以给每一个元素value赋予一个权重score，另一方面它又类似于TreeSet，内部的元素会按照权重score进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表。 zset底层使用了两个数据结构 （1）hash，hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。 （2）跳跃表，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表。 跳跃表简介有序集合在生活中比较常见，例如根据成绩对学生排名，根据得分对玩家排名等。对于有序集合的底层实现，可以用数组、平衡树、链表等。数组不便元素的插入、删除；平衡树或红黑树虽然效率高但结构复杂；链表查询需要遍历所有效率低。Redis采用的是跳跃表。跳跃表效率堪比红黑树，实现远比红黑树简单。 实例对比有序链表和跳跃表，从链表中查询出51 （1） 有序链表 要查找值为51的元素，需要从第一个元素开始依次查找、比较才能找到。共需要6次比较。 （2） 跳跃表 从第2层开始，1节点比51节点小，向后比较。 21节点比51节点小，继续向后比较，后面就是NULL了，所以从21节点向下到第1层 在第1层，41节点比51节点小，继续向后，61节点比51节点大，所以从41向下 在第0层，51节点为要查找的节点，节点被找到，共查找4次。 从此可以看出跳跃表比有序链表效率要高","categories":[],"tags":[]},{"title":"全面了解Nginx如何配置","slug":"nginx","date":"2021-10-06T13:01:24.000Z","updated":"2021-10-11T04:11:43.152Z","comments":true,"path":"2021/10/06/nginx/","link":"","permalink":"https://luxiaobai.cn/2021/10/06/nginx/","excerpt":"","text":"[toc] 介绍NginxNginx是一个高性能的HTTP和反向代理Web服务器.同时也提供了IMAP/POP3/SMTP服务.占有内存少、并发能力强。 正向代理在客户端（浏览器）配置代理服务器，通过代理服务器进行互联网访问 反向代理客户端对代理是无感知的，不需要任何配置就可以访问。只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器IP地址。 负载均衡并发请求时，将请求分发到多个服务器上，将负载分发到不同的服务器 动静分离为加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。 Nginx配置文件第一部分: 全局块从配置文件开始到events块之间的内容，主要会设置一些影响Nginx服务器整体运行的配置指令，主要包括：配置运行Nginx服务器的用户（组）、运行生成的worker process数、进程PID存放路径、日志存放路径和类型以及配置文件的引入等。 1worker_processes 1; ##worker_processes值越大，可以支持的并发处理量也越多 第二部分: events主要影响Nginx服务器与用户的网络连接，常用设置包括是否开启对多workprocess下的网络连接进行序列化，是否允许同时接收多个网络连接，选取那种事件驱动模型来处理连接请求，每个word process可以同时支持的最大连接数等。 1234events &#123; worker_connections 768; ##支持的最大连接数 # multi_accept on;&#125; 第三部分:http块http块包括：http块和server块 http块： 配置指令包括文件引入、MIME-TYPE定义、日志自定义、连接超时时间、单链接请求数上限等。 server块： 全局server块：本虚拟机主机的监听配置和本虚拟机主机的名称或IP配置 location块：一个server块可以配置多个location块。主要作用是基于Nginx服务器接收到的请求字符串（例如server_name/uri-string)，对虚拟主机名称（也可以是IP别名）之外的字符串（例如前面的/uri-string)进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，以及第三方模块的配置也在这里进行。 Nginx源码安装1234567891011##CentOS 安装yum -y install gccyum install -y pcre pcre-develyum install -y zlib zlib-develyum install -y openssl openssl-develwget http://nginx.org/download/nginx-1.9.9.tar.gztar -zxvf nginx-1.9.9.tar.gzcd nginx-1.9.9./configuremakemake install 注意:如果连接不上，检查阿里云安全组是否开放端口，或者服务器防火墙是否开放端口 12345678910111213141516171819202122232425262728#开启service firewalld start#重启service firewalld restart#关闭service firewalld stop#查看防火墙规则firewall-cmd --list-all#查询端口是否开放firewall-cmd --query-port=8080/tcp#开放80端口firewall-cmd --permanent --add-port=80/tcp#移除端口firewall-cmd --permanent --remove-port=8080/tcp#重启防火墙（修改配置后要重启防火墙)firewall-cmd --reload##参数解释firwall-cmd:是Linux提供的操作firewall的一个工具： --permanent：表示设置为持久 --add-port：标识添加的端口 Nginx功能模块配置反向代理请求转发配置12345678server&#123; listen 8080; server_name: 192.168.17.219; root /home/project/DIANBoard/build; location / &#123; proxy_pass http://127.0.0.1:8888; &#125;&#125; 使用Nginx反向代理，根据访问的路径跳转到不同端口的服务中，Nginx监听9001 访问http://127.0.0.1:9001/edu/ 直接跳转到127.0.0.1:8080 访问http://127.0.0.1:9001/vod/ 直接跳转到127.0.0.1:8081 1234567891011121314151617server &#123; listen 9091; server_name localhost; //允许cros跨域访问 add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27;; #proxy_redirect default; #跟代理服务器连接的超时时间，必须留意这个time out时间不能超过75秒，当一台服务器当掉时，过10秒转发到另外一台服务器。 proxy_connect_timeout 10; location ~ /edu/ &#123; proxy_pass http://127.0.0.1:8080; &#125; location ~ /vod/ &#123; proxy_pass http://127.0.0.1:8081; &#125;&#125; location指令说明用于匹配URL 123location [ = | ~ | ~* | ^~] uri &#123; &#125; =：用于不含正则表达式的URI前，要求请求字符串与URI严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求 ~：用于表示URI包含正则表达式，并且区分大小写。 ~*：用于表示URI包含正则表达式，并且不区分大小写 *~：用于不含正则表达式的URI前，要求Nginx服务器找到标识URI和请求字符串匹配度最高的location后，立即使用此location处理请求，而不再使用location块中的正则URI和请求字符串做匹配。 *注意：如果URI包含正则表达式，则必须要有~ 或者 ~标识。 负载均衡12345678910111213141516171819http&#123; ... upstream myserver&#123; ip_hash; server 121.199.76.44:8080; server 121.199.76.44:8081 &#125; server&#123; listen 7777; server_name localhost; root /myproject/build; location / &#123; .... proxy_pass http://myserver; proxy_connection_timeout 10; &#125; &#125;&#125; 1.轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。2.weight：weight代表权重默认为1，权重越高被分配的客户端越多。1234upstream myserver&#123; server 121.199.76.44:8080 weight=1; server 121.199.76.44:8081 weight=1; &#125; 3.ip_hash：每个请求按访问IP的hash结果分配，这样每个请求固定访问一个后端服务器。可以解决session的问题。12345upstream myserver&#123; ip_hash; server 121.199.76.44:8080; server 121.199.76.44:8081; &#125; 4.fair（第三方）：按后端服务器的响应时间来分配请求，响应时间短的优先分配。12345upstream myserver&#123; server 121.199.76.44; server 121.199.76.44; fair;&#125; 动静分离将动态跟静态请求分开，不能理解成只是单纯的把动态页面和静态页面物理分离。严格意义上说应该是动态请求跟静态请求分开，可以理解成使用Nginx处理静态页面，Tomcat处理动态页面。 动静分离实现角度： 纯粹把静态文件独立成单独的域名，放在独立的服务器上 动态和静态文件混合在一起发布，通过Nginx来分开。 通过location指定不同的后缀名实现不同的请求转发。通过expires参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。 Expires：是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可，所以不会产生额外的流量。此方法非常适合不经常变动的资源。（如果经常更新的文件，不建议使用Expires来缓存），3d，表示3天之内访问这个URL，发送一个请求，比对服务器改文件最后更新时间没有变化，则不会从服务器抓取，返回状态码304， 如果有修改，则直接从服务器重新下载，返回状态码200。 创建data目录，分别放data/a.html和image/1.jpeg 123456789location /www/ &#123; root /data/; index index.html index.htm;&#125;location /image/ &#123; root /data/; autoindex on; #列出当前文件中的内容 &#125; Nginx限流限制访问评率(正常流量)采用 ngx_http_limit_req_module模块来限制请求的访问频率，基于漏桶算法原理实现 使用 nginx limit_req_zone 和 limit_req 两个指令，限制单个IP的请求处理速率 12345678910http&#123; limit_req_zone $binary_remote_addr zone=serviceRateLimit:10m rate=10r/s //每秒最多处理10个请求&#125;server&#123; location / &#123; limit_req zone=servicelRateLimit; proxy_pass http://upstream_clusterl; &#125;&#125; 语法:limit_req_zone key zone rate key:定义限流对象,binary_remote_addr是一种key,表示基于remote_addr(客户端IP)来做限流,binary_的目的是压缩内存占用量 zone:定义共享内存区来存储访问信息， myRateLimit:10m 表示一个大小为10M，名字为myRateLimit的内存区域。1M能存储16000 IP地址的访问信息，10M可以存储16W IP地址访问信息。 rate:用于设置最大访问速率，rate=10r/s 表示每秒最多处理10个请求。Nginx 实际上以毫秒为粒度来跟踪请求信息，因此 10r/s 实际上是限制：每100毫秒处理一个请求。这意味着，自上一个请求处理完后，若后续100毫秒内又有请求到达，将拒绝处理该请求 限制并发连接数(突发流量)按上面的配置在流量突然增大时，超出的请求将被拒绝，无法处理突发流量，那么在处理突发流量的时候，该怎么处理呢？Nginx提供了 burst 参数来解决突发流量的问题，并结合 nodelay 参数一起使用。burst 译为突发、爆发，表示在超过设定的处理速率后能额外处理的请求数。 12345678910http&#123; limit_req_zone $binary_remote_addr zone=serviceRateLimit:10m rate=10r/s //每秒最多处理10个请求&#125;server&#123; location / &#123; limit_req zone=servicelRateLimit burst=20 nodelay; proxy_pass http://upstream_clusterl; &#125;&#125; burst=20 nodelay表示这20个请求立马处理，不能延迟，相当于特事特办。不过，即使这20个突发请求立马处理结束，后续来了请求也不会立马处理。burst=20 相当于缓存队列中占了20个坑，即使请求被处理了，这20个位置这只能按 100ms一个来释放。这就达到了速率稳定，但突然流量也能正常处理的效果。 限制并发连接数ngx_http_limit_conn_module模块提供了对资源连接数进行限制的功能，使用 limit_conn_zone 和 limit_conn 两个指令 12345678910http&#123; limit_conn_zone $binary_remote_addr zone=perip:10m; limit_conn_zone $server_name zone=perserver:10m;&#125;server&#123; ... limit_conn perip 20; //限制单个IP同时最多能持有10连接 limit_conn perserver 100; //限制server的最大连接数&#125; limit_conn perip 20：对应的key是 $binary_remote_addr，表示限制单个IP同时最多能持有20个连接。 limit_conn perserver 100：对应的key是 $server_name，表示虚拟主机(server) 同时能处理并发连接的总数。注意，只有当 request header 被后端server处理后，这个连接才进行计数。 缓存1、浏览器缓存,静态资源缓存用expire123456location ~ .*\\.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|mp4|ogg|ogv|webm)$ &#123; expires 7d;&#125;location ~ .*\\.(?:js|css)$ &#123; expires 7d;&#125; 2、代理层缓存1234567891011121314151617proxy_cache_path /data/cache/nginx/ levels=1:2 keys_zone=cache:512m inactive = 1d max_size=8g;location / &#123; location ~ \\.(htm|html)?$ &#123; proxy_cache cache; proxy_cache_key $uri$is_args$args; //以此变量值做HASH,作为KEY add_header X-Cache $upstream_cache_status; proxy_cache_valid 200 10m; proxy_cache_valid any 1m; proxy_pass http://real_server; proxy_redirect off; &#125; location ~ .*\\.(gif|jpg|jpeg|bmp|png|ico|txt|js|css)$&#123; root /data/webapps/edc; expires 3d; add_header Static Nginx-Proxy; &#125;&#125; 黑白名单1、不限流白名单123456789101112131415geo $limit &#123; 122.16.11.0/24 0;&#125;map $limit $limit_key&#123; 1 $binary_remote_addr; 0 &quot;&quot;;&#125;limit_req_zone $limit_key zone=mylimit:10m rate=1r/s;location / &#123; limit_req zone=mylimit burst=1 nodelay; proxy_pass http://serveic3Cluster;&#125; 2、黑名单1234567location / &#123; deny 10.52.119.21; deny 11.12.123.1/24; allow 10.1.1.0/16; allow 1001:0dby::/32; deny all;&#125; Nginx配置高可用的集群 Keepalived 工作原理：vrrp协议实现 工作方式：抢占式和非抢占式 高可用：两台业务系统启动相同服务，如果有一台宕机，另一台自动接管，即高可用 安装配置keepalived： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#两条服务器安装yum install keepalived -y##Ubuntu 安装keepalivedsudo apt-get install libssl-devsudo apt-get install opensslsudo apt-get install libpopt-devsudo apt-get install keepalived#配置keepalived.confsudo vim /etc/keepalived/keepalived.confglobal_defs &#123; #全局定义 notifaction_email &#123; 1575018859@qq.com &#125; notification_email_from sns-lvs@gmail.com smtp_server smtp.hysec.com smtp_connection_timeout 30 router_id nginx_master #设置Nginx master的ID，在一个网络应该是唯一的,访问到主机&#125;vrrp_script chk_http_port &#123; script &quot;/usr/local/src/check_nginx_pid.sh&quot; ##最后手动执行下次脚本，以确保此脚本能够正常执行 interval 2 ##(检测脚本执行的间隔，单位是秒) weight 2&#125;vrrp_instance VI_1 &#123; state MASTER #指定keepalived的角色，MASTER为主，BACKUP为备 interface eth0 #当前进行vrrp通讯的网络接口卡（当前centos的网卡),使用 ifconfig查看 virtual_router_id 66 #虚拟路由编号，主从要一致 priority 100 #优先级，数值越大，获取处理请求的优先级越高 advert_int 1 #检查间隔，默认为ls（vrrp组播周期秒数) authentication &#123; auth_type PASS auth_pass 1111 &#125; track_script&#123; chk_http_port #调用检测脚本 &#125; virtual_ipaddress &#123; 121.199.76.44 ##定义虚拟IP（VIP），可多设，每行一个 &#125;&#125;##创建Nginx服务监控脚本/usr/local/nginx/check_nginx.sh（主从服务器一致）sudo vim /usr/local/src/check_nginx_pid.sh#!/bin/bashA=`ps -C nginx --no-header |wc -l`if [ $A -eq 0 ];then #/usr/local/nginx/sbin/nginx #重启Nginx sudo service nginx restart if [ `ps -C nginx --no-header | wc -l` -eq 0];then #Nginx重启失败，则停掉keepalived服务 killall keepalived fifi ###另外检测脚本 #!/bin/sh nginxpid=$(ps -C nginx --no-header|wc -l) #1.判断Nginx是否存活，如果不存活则尝试启动Nginx if [$nginxpid -eq 0 ];then systemctl start nginx sleep 3 #2.等待3秒后再次获取一次Nginx状态 nginxpid=$(ps -C nginx --no-header|wc -l) #3.再次进行判断,如Nginx还不存活则停止keepalived,让地址进行漂移,并退出脚本 if[$nginxpid -eq 0];then systemctl stop keepalived fi fi 日志存放位置：/var/log/messages 程序目录：/etc/keepalived/keepalivd.conf 启动nginx和keepalived 1systemctl start keepalived.service 一个master和多个worker的好处 可以使用nginx -s reload 热部署,利用nginx进行热部署操作 每个worker是独立的进程,如果有其中的一个worker出现问题,其他worker独立的,继续进行争抢,实现请求过程,不会造成服务中断 设置多少个worker ?worker数和服务器的cpu数相等时最为适宜的 连接数worker_connection 发送请求,占有worker的几个连接数:2个(静态)或者4个(动态) nginx有一个master, 有4个worker,每个worker支持最大的连接数据1024,支持的最大并发数多少? ##普通的静态访问最大并发数是:worker_connections * worker_processes / 2, ##而如果是http作为反向代理,最大并发数:worker_connections * worker_processes / 4","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2021-10-04T03:35:04.791Z","updated":"2021-10-11T02:58:11.794Z","comments":true,"path":"2021/10/04/hello-world/","link":"","permalink":"https://luxiaobai.cn/2021/10/04/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[]}